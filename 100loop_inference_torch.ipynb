{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100loop_inference.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/iYl5fcrSvmW19kWN3QtJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hihunjin/Code-snippet-for-everything/blob/main/100loop_inference_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93FtXOdAC65-",
        "outputId": "327ffb3b-3fc4-4734-d2af-020b82f3cb95"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 225 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 276 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 286 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 327 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 337 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 376 kB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euWp8EFcC-v0"
      },
      "source": [
        "import torch\n",
        "import timm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkhiOu_bDJOc"
      },
      "source": [
        "num_classes = 10\n",
        "device = \"cuda\"\n",
        "model = timm.create_model(\"resnet18\", num_classes=num_classes, pretrained=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQLNI3UoDKVU"
      },
      "source": [
        "model.to(device);"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sorbAOhHDNMh"
      },
      "source": [
        "img_size = 1100\n",
        "batch = 10\n",
        "# inference\n",
        "model.eval()\n",
        "for i in range(100):\n",
        "    \"\"\"training loop for one batch\"\"\"\n",
        "    #get images and labels\n",
        "    inputs, target = torch.rand(batch, 3,img_size,img_size), torch.randint(0,num_classes,(batch,)) # torch.empty(batch, dtype=torch.long).random_(num_classes)\n",
        "    #move data to gpu\n",
        "    inputs, target = inputs.to(device), target.to(device)\n",
        "    output = model(inputs)\n",
        "    # loss = torch.nn.CrossEntropyLoss()(output, target)\n",
        "    # loss.backward()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npY4egvHDPHP",
        "outputId": "5426f558-6122-446b-bd26-a780d09d4c97"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 29 04:56:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    66W / 300W |  12581MiB / 16160MiB |     48%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}