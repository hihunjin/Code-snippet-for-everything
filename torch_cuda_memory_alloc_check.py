import torch

def print_mem():
    print('----------')
    print('mem_all', torch.cuda.memory_allocated(0))
    print('mem_all_max', torch.cuda.max_memory_allocated(0))
    print('----------')

torch.cuda.init()
out = torch.randn(20,20,20,20*10000//2) #3.2GB
d = out.cuda()
print_mem()
# ----------
# mem_all 3200253952
# mem_all_max 3200253952
# ----------
print(torch.cuda.memory_summary(0))
# |===========================================================================|
# |                  PyTorch CUDA memory summary, device ID 0                 |
# |---------------------------------------------------------------------------|
# |            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
# |===========================================================================|
# |        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
# |---------------------------------------------------------------------------|
# | Allocated memory      |    3052 MB |    3052 MB |    3052 MB |       0 B  |
# |       from large pool |    3052 MB |    3052 MB |    3052 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | Active memory         |    3052 MB |    3052 MB |    3052 MB |       0 B  |
# |       from large pool |    3052 MB |    3052 MB |    3052 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | GPU reserved memory   |    3052 MB |    3052 MB |    3052 MB |       0 B  |
# |       from large pool |    3052 MB |    3052 MB |    3052 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Allocations           |       1    |       1    |       1    |       0    |
# |       from large pool |       1    |       1    |       1    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Active allocs         |       1    |       1    |       1    |       0    |
# |       from large pool |       1    |       1    |       1    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | GPU reserved segments |       1    |       1    |       1    |       0    |
# |       from large pool |       1    |       1    |       1    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Non-releasable allocs |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize allocations  |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize GPU segments |       0    |       0    |       0    |       0    |
# |===========================================================================|


out2 = torch.randn(20,20,20,20*10000//2) #3.2GB
d2 = out2.cuda()
print_mem()
# ----------
# mem_all 6400507904
# mem_all_max 6400507904
# ----------
print(torch.cuda.memory_summary(0))
# |===========================================================================|
# |                  PyTorch CUDA memory summary, device ID 0                 |
# |---------------------------------------------------------------------------|
# |            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
# |===========================================================================|
# |        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
# |---------------------------------------------------------------------------|
# | Allocated memory      |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from large pool |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | Active memory         |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from large pool |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | GPU reserved memory   |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from large pool |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Allocations           |       2    |       2    |       2    |       0    |
# |       from large pool |       2    |       2    |       2    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Active allocs         |       2    |       2    |       2    |       0    |
# |       from large pool |       2    |       2    |       2    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | GPU reserved segments |       2    |       2    |       2    |       0    |
# |       from large pool |       2    |       2    |       2    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Non-releasable allocs |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize allocations  |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize GPU segments |       0    |       0    |       0    |       0    |
# |===========================================================================|


del d
print_mem()
# ----------
# mem_all 3200253952
# mem_all_max 6400507904
# ----------
print(torch.cuda.memory_summary(0))
# |===========================================================================|
# |                  PyTorch CUDA memory summary, device ID 0                 |
# |---------------------------------------------------------------------------|
# |            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
# |===========================================================================|
# |        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
# |---------------------------------------------------------------------------|
# | Allocated memory      |    3052 MB |    6104 MB |    6104 MB |    3052 MB |
# |       from large pool |    3052 MB |    6104 MB |    6104 MB |    3052 MB |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 MB |
# |---------------------------------------------------------------------------|
# | Active memory         |    3052 MB |    6104 MB |    6104 MB |    3052 MB |
# |       from large pool |    3052 MB |    6104 MB |    6104 MB |    3052 MB |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 MB |
# |---------------------------------------------------------------------------|
# | GPU reserved memory   |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from large pool |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Allocations           |       1    |       2    |       2    |       1    |
# |       from large pool |       1    |       2    |       2    |       1    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Active allocs         |       1    |       2    |       2    |       1    |
# |       from large pool |       1    |       2    |       2    |       1    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | GPU reserved segments |       2    |       2    |       2    |       0    |
# |       from large pool |       2    |       2    |       2    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Non-releasable allocs |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize allocations  |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize GPU segments |       0    |       0    |       0    |       0    |
# |===========================================================================|


out3 = torch.randn(20,20,20,20*10000//2) #3.2GB
d3 = out3.cuda()
print_mem()
# ----------
# mem_all 6400507904
# mem_all_max 6400507904
# ----------
print(torch.cuda.memory_summary(0))
# |===========================================================================|
# |                  PyTorch CUDA memory summary, device ID 0                 |
# |---------------------------------------------------------------------------|
# |            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
# |===========================================================================|
# |        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
# |---------------------------------------------------------------------------|
# | Allocated memory      |    6104 MB |    6104 MB |    9156 MB |    3052 MB |
# |       from large pool |    6104 MB |    6104 MB |    9156 MB |    3052 MB |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 MB |
# |---------------------------------------------------------------------------|
# | Active memory         |    6104 MB |    6104 MB |    9156 MB |    3052 MB |
# |       from large pool |    6104 MB |    6104 MB |    9156 MB |    3052 MB |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 MB |
# |---------------------------------------------------------------------------|
# | GPU reserved memory   |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from large pool |    6104 MB |    6104 MB |    6104 MB |       0 B  |
# |       from small pool |       0 MB |       0 MB |       0 MB |       0 B  |
# |---------------------------------------------------------------------------|
# | Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Allocations           |       2    |       2    |       3    |       1    |
# |       from large pool |       2    |       2    |       3    |       1    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Active allocs         |       2    |       2    |       3    |       1    |
# |       from large pool |       2    |       2    |       3    |       1    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | GPU reserved segments |       2    |       2    |       2    |       0    |
# |       from large pool |       2    |       2    |       2    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Non-releasable allocs |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize allocations  |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize GPU segments |       0    |       0    |       0    |       0    |
# |===========================================================================|


print(torch.cuda.memory_summary(1))
# |===========================================================================|
# |                  PyTorch CUDA memory summary, device ID 1                 |
# |---------------------------------------------------------------------------|
# |            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
# |===========================================================================|
# |        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
# |---------------------------------------------------------------------------|
# | Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
# |---------------------------------------------------------------------------|
# | Allocations           |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Active allocs         |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | GPU reserved segments |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Non-releasable allocs |       0    |       0    |       0    |       0    |
# |       from large pool |       0    |       0    |       0    |       0    |
# |       from small pool |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize allocations  |       0    |       0    |       0    |       0    |
# |---------------------------------------------------------------------------|
# | Oversize GPU segments |       0    |       0    |       0    |       0    |
# |===========================================================================|



## 결론 : ``torch.cuda.max_memory_allocated(0)``만 보면 된다.
