{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_cuda_set_gpu_limit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4J26X60JRx3VofBbIg/2u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hihunjin/Code-snippet-for-everything/blob/main/torch_cuda_set_gpu_limit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3CeH8kidp0D"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVlA1N0EdqK2",
        "outputId": "ddf84932-d964-4834-a77f-5766b0f7ec3a"
      },
      "source": [
        "total_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "print(total_memory)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11996954624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uuhDrYgdq0k",
        "outputId": "95a58aee-5d03-4038-877f-80ae8d60b865"
      },
      "source": [
        "img_size = int(1000*13)\n",
        "t = torch.rand(img_size,img_size)\n",
        "t.cuda()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1633, 0.3163, 0.8002,  ..., 0.2970, 0.4642, 0.0643],\n",
              "        [0.7856, 0.7169, 0.2118,  ..., 0.2550, 0.2931, 0.3715],\n",
              "        [0.4302, 0.9916, 0.1702,  ..., 0.9652, 0.4889, 0.1864],\n",
              "        ...,\n",
              "        [0.5449, 0.7296, 0.0374,  ..., 0.0835, 0.2682, 0.7645],\n",
              "        [0.3558, 0.5489, 0.3336,  ..., 0.6939, 0.6209, 0.6848],\n",
              "        [0.5351, 0.6289, 0.6656,  ..., 0.3936, 0.8541, 0.5426]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYLEYYRHdzan"
      },
      "source": [
        "torch.cuda.set_per_process_memory_fraction(0.1, device=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC2x6vERd3EP",
        "outputId": "16f46dbb-efb6-48d9-e5bf-3204042922a2"
      },
      "source": [
        "img_size = int(1000*11)\n",
        "t = torch.rand(img_size,img_size)\n",
        "t.cuda()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0979, 0.9984, 0.6050,  ..., 0.8763, 0.8786, 0.6566],\n",
              "        [0.7019, 0.2018, 0.6851,  ..., 0.3873, 0.2105, 0.9866],\n",
              "        [0.2037, 0.4767, 0.0257,  ..., 0.8015, 0.6475, 0.7626],\n",
              "        ...,\n",
              "        [0.3943, 0.2826, 0.2999,  ..., 0.0804, 0.1855, 0.5737],\n",
              "        [0.8979, 0.7290, 0.4128,  ..., 0.4768, 0.4111, 0.0766],\n",
              "        [0.2784, 0.1051, 0.4346,  ..., 0.4198, 0.3586, 0.9363]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDsas4j5eAaj",
        "outputId": "8c7e944d-e1b1-4fa1-8ed3-11a7e007a1bd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 29 06:55:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    73W / 149W |   1624MiB / 11441MiB |     29%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "GODUgSifd-U8",
        "outputId": "fe079ea2-bdb0-40cd-f3d4-d9680f90b211"
      },
      "source": [
        "img_size = int(1000*12)\n",
        "t = torch.rand(img_size,img_size)\n",
        "t.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f48058848705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 550.00 MiB (GPU 0; 11.17 GiB total capacity; 1.08 GiB already allocated; 9.59 GiB free; 1.12 GiB allowed; 1.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}